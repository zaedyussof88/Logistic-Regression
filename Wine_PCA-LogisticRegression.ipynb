{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VQ3syspj_rKn"
   },
   "source": [
    "# Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xJGl9TcT_skx"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BNEgrGwd_29D"
   },
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hyp1gza1_6qX"
   },
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lPLTDBVI__ZQ"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_Acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Ash_Alcanity</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_Phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_Intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Customer_Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malic_Acid   Ash  Ash_Alcanity  Magnesium  Total_Phenols  \\\n",
       "0      14.23        1.71  2.43          15.6        127           2.80   \n",
       "1      13.20        1.78  2.14          11.2        100           2.65   \n",
       "2      13.16        2.36  2.67          18.6        101           2.80   \n",
       "3      14.37        1.95  2.50          16.8        113           3.85   \n",
       "4      13.24        2.59  2.87          21.0        118           2.80   \n",
       "..       ...         ...   ...           ...        ...            ...   \n",
       "173    13.71        5.65  2.45          20.5         95           1.68   \n",
       "174    13.40        3.91  2.48          23.0        102           1.80   \n",
       "175    13.27        4.28  2.26          20.0        120           1.59   \n",
       "176    13.17        2.59  2.37          20.0        120           1.65   \n",
       "177    14.13        4.10  2.74          24.5         96           2.05   \n",
       "\n",
       "     Flavanoids  Nonflavanoid_Phenols  Proanthocyanins  Color_Intensity   Hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     OD280  Proline  Customer_Segment  \n",
       "0     3.92     1065                 1  \n",
       "1     3.40     1050                 1  \n",
       "2     3.17     1185                 1  \n",
       "3     3.45     1480                 1  \n",
       "4     2.93      735                 1  \n",
       "..     ...      ...               ...  \n",
       "173   1.74      740                 3  \n",
       "174   1.56      750                 3  \n",
       "175   1.56      835                 3  \n",
       "176   1.62      840                 3  \n",
       "177   1.60      560                 3  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
      " ...\n",
      " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
      " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
      " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.371e+01, 1.860e+00, 2.360e+00, ..., 1.110e+00, 4.000e+00,\n",
       "        1.035e+03],\n",
       "       [1.222e+01, 1.290e+00, 1.940e+00, ..., 8.600e-01, 3.020e+00,\n",
       "        3.120e+02],\n",
       "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "        8.350e+02],\n",
       "       ...,\n",
       "       [1.242e+01, 1.610e+00, 2.190e+00, ..., 1.060e+00, 2.960e+00,\n",
       "        3.450e+02],\n",
       "       [1.390e+01, 1.680e+00, 2.120e+00, ..., 9.100e-01, 3.330e+00,\n",
       "        9.850e+02],\n",
       "       [1.416e+01, 2.510e+00, 2.480e+00, ..., 6.200e-01, 1.710e+00,\n",
       "        6.600e+02]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1wrHODfJAEiI"
   },
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W-UCD7ezAJG2"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.91083058, -0.46259897, -0.01142613, ...,  0.65706596,\n",
       "         1.94354495,  0.93700997],\n",
       "       [-0.95609928, -0.96608672, -1.53725357, ..., -0.40859506,\n",
       "         0.58118003, -1.41336684],\n",
       "       [ 0.35952243,  1.67501572, -0.37471838, ..., -1.55950896,\n",
       "        -1.44846566,  0.28683658],\n",
       "       ...,\n",
       "       [-0.70550467, -0.68342693, -0.62902295, ...,  0.44393375,\n",
       "         0.49776993, -1.30608823],\n",
       "       [ 1.14889546, -0.6215951 , -0.88332752, ..., -0.19546286,\n",
       "         1.0121322 ,  0.77446662],\n",
       "       [ 1.47466845,  0.11155374,  0.42452457, ..., -1.43162964,\n",
       "        -1.23994042, -0.28206514]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S3i3lRiwASAX"
   },
   "source": [
    "## Applying PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fit the PCA model\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues:\n",
      "[4.8923083  2.46635032 1.42809973 1.01233462 0.84906459 0.60181514\n",
      " 0.52251546 0.33051429 0.29595018 0.2399553  0.21432212 0.16831254\n",
      " 0.08414846]\n",
      "\n",
      "Eigenvectors:\n",
      "[[ 1.46698114e-01 -2.42245536e-01 -2.99344215e-02 -2.55190023e-01\n",
      "   1.20797723e-01  3.89344551e-01  4.23264856e-01 -3.06349555e-01\n",
      "   3.05722194e-01 -9.86919131e-02  3.00325353e-01  3.68211538e-01\n",
      "   2.92597130e-01]\n",
      " [-5.04170789e-01 -2.42168894e-01 -2.86984836e-01  6.46871827e-02\n",
      "  -2.29953850e-01 -9.36399132e-02 -1.08862204e-02 -1.87021637e-02\n",
      "  -3.04035180e-02 -5.45270809e-01  2.79243218e-01  1.74365000e-01\n",
      "  -3.63154608e-01]\n",
      " [ 1.17235150e-01 -1.49946576e-01 -6.56394387e-01 -5.84282337e-01\n",
      "  -8.22627466e-02 -1.80804417e-01 -1.42959330e-01 -1.72234753e-01\n",
      "  -1.58362102e-01  1.42421708e-01 -9.32387182e-02 -1.96077407e-01\n",
      "   9.73171134e-02]\n",
      " [-2.06254611e-01 -1.30489298e-01 -1.51536318e-02  9.04220851e-02\n",
      "   8.39128346e-01 -1.93179478e-01 -1.40459548e-01 -3.37332618e-01\n",
      "   1.14752900e-01 -7.87857057e-02 -2.41740256e-02 -1.84028641e-01\n",
      "  -5.67677845e-02]\n",
      " [-1.87815947e-01  5.68639776e-01 -2.99209426e-01 -4.12499478e-02\n",
      "  -2.71971315e-02  1.40645426e-01  9.26866486e-02 -8.58416771e-02\n",
      "   5.65105241e-01  1.32346052e-02 -3.72610811e-01  8.93796748e-02\n",
      "  -2.17529485e-01]\n",
      " [-1.48851318e-01 -2.69052764e-01 -9.33386061e-02 -1.01342392e-01\n",
      "   1.12567350e-01  1.22248798e-02 -5.50345182e-02  6.95340883e-01\n",
      "   4.98354410e-01  1.59452160e-01  2.16515349e-01 -2.35172361e-01\n",
      "   1.05621383e-01]\n",
      " [-1.79263662e-01 -5.92636731e-01  6.07334578e-02  2.50323869e-01\n",
      "  -2.85240559e-01  5.31455344e-02  7.98994076e-02 -2.97371718e-01\n",
      "   2.02519133e-01  3.97364107e-01 -3.84654748e-01 -8.62903341e-02\n",
      "  -1.30298291e-01]\n",
      " [ 4.03054922e-01  1.01833706e-01 -3.51841423e-01  5.00457282e-01\n",
      "  -8.37391743e-02 -1.35111456e-01 -3.36016514e-03 -1.90120758e-01\n",
      "   1.76029939e-01  2.14930670e-01  5.17259438e-01 -1.36456039e-01\n",
      "  -1.67758429e-01]\n",
      " [ 4.17197583e-01 -2.17101488e-01 -1.28549846e-01 -4.73344124e-02\n",
      "   2.78918776e-01  2.80985650e-01  3.91442963e-02  2.78622194e-01\n",
      "  -1.48539457e-01  4.10240865e-03 -1.97814118e-01  2.38138151e-01\n",
      "  -6.37350206e-01]\n",
      " [ 4.13320786e-04 -8.78560762e-02 -4.52518598e-01  4.86169765e-01\n",
      "   1.14764951e-01  9.45645138e-02 -1.00444099e-01  2.00128778e-01\n",
      "  -1.39942067e-01 -1.15349466e-01 -3.02254353e-01  3.18414303e-01\n",
      "   5.03247839e-01]\n",
      " [ 4.03567189e-01 -1.52474999e-01  1.68376064e-01 -6.70902926e-02\n",
      "  -1.02396856e-01 -6.18600153e-01 -1.39680277e-01  1.63323514e-03\n",
      "   3.88568490e-01 -3.08345904e-01 -2.00456386e-01  2.84100327e-01\n",
      "   3.75546771e-02]\n",
      " [-2.75660860e-01  8.13845005e-02  1.29751275e-02 -9.89088030e-02\n",
      "   9.59297663e-02 -2.83897644e-01 -1.16729207e-01  3.96566280e-02\n",
      "  -8.60602743e-02  5.71651893e-01  1.98844532e-01  6.50869713e-01\n",
      "  -7.12377082e-02]\n",
      " [-5.54687162e-02  3.32731614e-02 -1.00618575e-01  5.61658566e-02\n",
      "   9.58423947e-02 -4.21265116e-01  8.47224703e-01  1.66256803e-01\n",
      "  -1.66197468e-01  3.96173606e-02 -1.05383688e-01 -9.95055559e-02\n",
      "  -1.60661776e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Access eigenvalues and eigenvectors\n",
    "eigenvalues = pca.explained_variance_\n",
    "eigenvectors = pca.components_\n",
    "\n",
    "# Display the results\n",
    "print(\"Eigenvalues:\")\n",
    "print(eigenvalues)\n",
    "\n",
    "print(\"\\nEigenvectors:\")\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Covariance Matrix:\n",
      "[[ 1.00813008  0.08797701  0.23066952 -0.32868099  0.2141631   0.35576761\n",
      "   0.2991246  -0.16913744  0.09649074  0.56962271 -0.04781543  0.07403492\n",
      "   0.63277882]\n",
      " [ 0.08797701  1.00813008  0.2016416   0.30658143 -0.06030917 -0.30124242\n",
      "  -0.41221162  0.36616593 -0.19190146  0.30749173 -0.54992807 -0.39352761\n",
      "  -0.20253906]\n",
      " [ 0.23066952  0.2016416   1.00813008  0.44971971  0.18321413  0.12235533\n",
      "   0.06130256  0.18655693 -0.02607834  0.24555355 -0.10928021 -0.01820002\n",
      "   0.15948032]\n",
      " [-0.32868099  0.30658143  0.44971971  1.00813008 -0.08930998 -0.37018442\n",
      "  -0.41804463  0.40212108 -0.25765667 -0.03090225 -0.25313262 -0.28934372\n",
      "  -0.48504311]\n",
      " [ 0.2141631  -0.06030917  0.18321413 -0.08930998  1.00813008  0.16513295\n",
      "   0.14458703 -0.30763563  0.27228619  0.1260674   0.05792599  0.01596134\n",
      "   0.31461066]\n",
      " [ 0.35576761 -0.30124242  0.12235533 -0.37018442  0.16513295  1.00813008\n",
      "   0.88119961 -0.45396901  0.6196806  -0.06935051  0.45718802  0.72214462\n",
      "   0.56326772]\n",
      " [ 0.2991246  -0.41221162  0.06130256 -0.41804463  0.14458703  0.88119961\n",
      "   1.00813008 -0.58329952  0.66598997 -0.19183675  0.58331869  0.80205789\n",
      "   0.55759374]\n",
      " [-0.16913744  0.36616593  0.18655693  0.40212108 -0.30763563 -0.45396901\n",
      "  -0.58329952  1.00813008 -0.35394023  0.15451294 -0.3178224  -0.49379349\n",
      "  -0.36456587]\n",
      " [ 0.09649074 -0.19190146 -0.02607834 -0.25765667  0.27228619  0.6196806\n",
      "   0.66598997 -0.35394023  1.00813008 -0.07018068  0.32282167  0.51036557\n",
      "   0.35552117]\n",
      " [ 0.56962271  0.30749173  0.24555355 -0.03090225  0.1260674  -0.06935051\n",
      "  -0.19183675  0.15451294 -0.07018068  1.00813008 -0.52395358 -0.45165752\n",
      "   0.31605457]\n",
      " [-0.04781543 -0.54992807 -0.10928021 -0.25313262  0.05792599  0.45718802\n",
      "   0.58331869 -0.3178224   0.32282167 -0.52395358  1.00813008  0.60022569\n",
      "   0.2452794 ]\n",
      " [ 0.07403492 -0.39352761 -0.01820002 -0.28934372  0.01596134  0.72214462\n",
      "   0.80205789 -0.49379349  0.51036557 -0.45165752  0.60022569  1.00813008\n",
      "   0.32437157]\n",
      " [ 0.63277882 -0.20253906  0.15948032 -0.48504311  0.31461066  0.56326772\n",
      "   0.55759374 -0.36456587  0.35552117  0.31605457  0.2452794   0.32437157\n",
      "   1.00813008]]\n"
     ]
    }
   ],
   "source": [
    "# Access covariance matrix\n",
    "covariance_matrix = pca.get_covariance()\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nCovariance Matrix:\")\n",
    "print(covariance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Explained Variance Ratio:\n",
      "[0.37329648 0.18818926 0.10896791 0.07724389 0.06478595 0.04592014\n",
      " 0.03986936 0.02521914 0.02258181 0.01830924 0.01635336 0.01284271\n",
      " 0.00642076]\n",
      "\n",
      "Cumulative Explained Variance:\n",
      "[0.37329648 0.56148574 0.67045365 0.74769754 0.81248349 0.85840362\n",
      " 0.89827298 0.92349212 0.94607393 0.96438317 0.98073654 0.99357924\n",
      " 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Calculate cumulative percentage of explained variance\n",
    "cumulative_explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "print(\"\\nCumulative Explained Variance:\")\n",
    "print(cumulative_explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Principal Components for 95% Variance: 10\n"
     ]
    }
   ],
   "source": [
    "# Find the number of principal components that explain 95% of the variance\n",
    "num_components_95_percent = np.argmax(cumulative_explained_variance >= 0.95) + 1\n",
    "\n",
    "# Display the results\n",
    "print(f\"\\nNumber of Principal Components for 95% Variance: {num_components_95_percent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fit the PCA model\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "num_components = 2 #Choose 2 because equavalant to 50%\n",
    "pca = PCA(n_components = num_components)\n",
    "X_train_pca1 = pca.fit_transform(X_train)\n",
    "X_test_pca1 = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.59891628, -0.00484089],\n",
       "       [ 0.15819134,  2.26659577],\n",
       "       [-2.6372337 , -2.66488569],\n",
       "       [-2.52848449, -0.51846618],\n",
       "       [ 1.70922581,  0.91719459],\n",
       "       [-2.83057003, -0.41936129],\n",
       "       [-2.82251879, -1.99763147],\n",
       "       [ 1.36618015, -0.04639099],\n",
       "       [-2.46584868,  0.07932269],\n",
       "       [-2.28554906,  0.40096658],\n",
       "       [ 1.14246632,  2.39587633],\n",
       "       [-2.28497881,  1.09274988],\n",
       "       [-2.52924945, -0.6477328 ],\n",
       "       [ 0.169245  ,  1.1264982 ],\n",
       "       [ 2.53088166, -1.05798498],\n",
       "       [-0.71596964,  2.80365836],\n",
       "       [ 2.46922033,  0.15871191],\n",
       "       [-0.58044574,  0.69290749],\n",
       "       [ 0.54583852, -0.41042188],\n",
       "       [ 3.5604963 , -1.42561284],\n",
       "       [ 1.58679826,  1.51260121],\n",
       "       [ 2.54872139,  0.05280515],\n",
       "       [-3.59338727, -0.88321901],\n",
       "       [-1.60406659, -2.40373662],\n",
       "       [ 1.48668426,  1.40863724],\n",
       "       [ 0.00830468,  2.04898307],\n",
       "       [-0.15646658,  2.80278355],\n",
       "       [-2.39863877, -2.47524175],\n",
       "       [-3.13549157,  0.29421321],\n",
       "       [ 3.30221023, -0.40939296],\n",
       "       [-3.53069904, -1.79971521],\n",
       "       [-0.45566459,  2.61242833],\n",
       "       [-0.58840115,  1.98301934],\n",
       "       [-1.16637216,  0.83784744],\n",
       "       [ 1.03763587,  1.37755233],\n",
       "       [ 1.95890184,  1.62578024],\n",
       "       [ 2.76990407, -1.86073384],\n",
       "       [ 2.06150478, -1.32280528],\n",
       "       [ 0.84107017,  2.00894711],\n",
       "       [ 3.52522122, -1.41880443],\n",
       "       [-3.82504747, -0.11741931],\n",
       "       [ 1.70427554,  0.46267479],\n",
       "       [-3.44482795, -0.89793105],\n",
       "       [ 3.14119715, -0.80251074],\n",
       "       [ 2.34148171, -1.69991384],\n",
       "       [ 1.25162098,  0.91305357],\n",
       "       [ 3.57847538, -1.78146353],\n",
       "       [ 0.93052986,  2.26747372],\n",
       "       [ 0.50457042,  1.9619121 ],\n",
       "       [ 3.82251943, -2.88150786],\n",
       "       [-2.3761711 , -2.15480504],\n",
       "       [-1.55524357,  1.38425679],\n",
       "       [ 2.51130377, -1.33358811],\n",
       "       [-0.72998664,  0.21814915],\n",
       "       [-0.77183165,  2.39360847],\n",
       "       [ 0.84583296,  1.51455514],\n",
       "       [-1.26515775, -0.04977931],\n",
       "       [ 2.20903303, -0.85715074],\n",
       "       [-3.89082853, -0.54194575],\n",
       "       [-1.8063292 , -1.31606219],\n",
       "       [ 4.37183355, -2.33594051],\n",
       "       [ 3.31126031, -1.43233851],\n",
       "       [-1.53830238,  1.9287237 ],\n",
       "       [-2.72256164, -2.15319971],\n",
       "       [ 2.81726412, -1.3810016 ],\n",
       "       [ 1.85165682, -0.74908527],\n",
       "       [-0.45023913,  2.16233055],\n",
       "       [-0.10551849,  1.20083745],\n",
       "       [ 1.96348867, -0.21556727],\n",
       "       [ 2.23499535, -1.29680173],\n",
       "       [ 0.81061036, -0.32968368],\n",
       "       [-3.28947263, -2.24576835],\n",
       "       [ 0.92542109,  0.76230572],\n",
       "       [ 2.3186051 ,  0.12948205],\n",
       "       [ 0.79856144,  1.42131736],\n",
       "       [-2.27737367, -0.55018386],\n",
       "       [ 3.14731552, -1.31152545],\n",
       "       [-1.73268901,  1.77855936],\n",
       "       [-2.85178367, -0.15732478],\n",
       "       [-2.682777  , -0.33277815],\n",
       "       [ 1.93435789, -1.6156844 ],\n",
       "       [ 1.61938048,  0.63200211],\n",
       "       [-2.04371299, -0.31389153],\n",
       "       [ 2.25520575, -1.89312658],\n",
       "       [-2.32821566, -0.18612349],\n",
       "       [-0.41435801,  1.98875351],\n",
       "       [ 1.44705447, -0.66672748],\n",
       "       [ 2.19851825, -0.68997732],\n",
       "       [-0.42257991,  1.94397583],\n",
       "       [ 2.76213322, -1.54543423],\n",
       "       [-2.84540302, -1.94250398],\n",
       "       [-1.5915982 ,  1.41522865],\n",
       "       [-3.35600644, -1.14127988],\n",
       "       [ 1.67829924, -0.10816612],\n",
       "       [-2.94150833, -0.3885073 ],\n",
       "       [-2.30405629, -2.15027517],\n",
       "       [-3.49291623, -1.29239829],\n",
       "       [ 2.33527547, -0.3435751 ],\n",
       "       [ 1.46219731,  2.05255915],\n",
       "       [-0.43118871,  2.4048574 ],\n",
       "       [ 0.42256584,  1.05544618],\n",
       "       [ 0.52658784,  3.87214144],\n",
       "       [-2.72797263, -1.58306403],\n",
       "       [-3.17868679, -2.71193573],\n",
       "       [-0.62158919,  1.0446325 ],\n",
       "       [-1.40436141,  1.47634167],\n",
       "       [ 0.91169846, -0.65475647],\n",
       "       [ 1.12423581,  1.34653907],\n",
       "       [-2.84547545, -1.32732299],\n",
       "       [-2.36335963, -2.43164111],\n",
       "       [ 2.54578547, -1.85201533],\n",
       "       [ 3.21543609, -1.84137496],\n",
       "       [-2.74703277, -0.19539224],\n",
       "       [-1.05186423,  1.83455849],\n",
       "       [-1.50826783,  0.99164925],\n",
       "       [-0.53471293,  2.50577398],\n",
       "       [ 1.40057023, -0.66105221],\n",
       "       [ 1.10794215, -0.24580628],\n",
       "       [ 2.83487283, -0.95812357],\n",
       "       [-0.52771371,  2.59472825],\n",
       "       [ 0.31128129,  2.28677331],\n",
       "       [-0.06526682,  2.04360861],\n",
       "       [ 2.91835495, -0.82035658],\n",
       "       [-2.40719925, -2.23612256]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7: Train logistic regression model on the transformed data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_reg_model = LogisticRegression()\n",
    "logistic_reg_model.fit(X_train_pca1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Predict and evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = logistic_reg_model.predict(X_test_pca1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "principal_component_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
